temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
getwd()
setwd("C:/Users/Derek/Documents/CS_work/scores_calculation")
load(".RData")
save(bg_scores, merged_data, merged_data_parcels, biking, amenity_info, file = "dashboard_data.RData")
setwd("C:/Users/Derek/Documents/CS_work/planning_dashboard_v2")
rm(list = ls(0))
rm(list = ls())
getwd(0)
getwd()
load("dashboard_data.RData")
load("dashboard_map_data.RData")
library(shiny)
library(sp)
library(leaflet)
library(googlesheets)
library(tidyr)
source("rank_fixer.R")
source("score_calc.R")
source("type_splitter.R")
source("weight_adder.R")
source("scenario.R")
# Libraries and code used for building
library(dplyr)
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
source("marg_good_func.R")
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
View(scenario)
View(scenario)
View(temp_merged)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
View(bg_scores)
View(bg_scores)
513.83130
load("dashboard_data.RData")
View(bg_scores)
load("dashboard_data.RData")
View(base_map)
View(base_map)
View(bg_scores)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
source('~/CS_work/planning_dashboard_v2/scenario.R')
toc()
# Libraries and code used for building
library(tictoc)
scenario <- function() {
# I don't think anything needs to be sent in, it just needs to return the new scores somehow.
tic()
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# View(type_counts)
# Really just for testing.
# parcel_proposals %>% group_by(type) %>% summarize(n())
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
# Now just need to append the two dataframes and update the ranks where appropriate
# For now, I'll just keep all but could easily trim each subset to only the desired amount of each amenity.
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
toc()
}
tic()
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# View(type_counts)
# Really just for testing.
# parcel_proposals %>% group_by(type) %>% summarize(n())
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
# Now just need to append the two dataframes and update the ranks where appropriate
# For now, I'll just keep all but could easily trim each subset to only the desired amount of each amenity.
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
toc()
View(bg_scores)
runApp()
View(subset(bg_scores, select = c(spatial_id, access_score2)))
bg_scores <- subset(bg_scores, select = c(spatial_id, access_score2))
names(bg_scores)[2] <- "baseline_score"
runApp()
View(base_map)
View(bg_scores)
save(bg_scores, merged_data, merged_data_parcels, biking, amenity_info, file = "dashboard_data.RData")
load("dashboard_data.RData")
View(bg_scores)
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
View(merged_data)
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:B60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
new_parcel_types <- unique(parcel_proposals$type)
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
temp_merged <- merged_data_parcels
temp_merged <- temp_merged %>% left_join(parcel_proposals, by = c("parcel" = "APN"))
temp_merged$rank <- NA
temp_merged$abs_good <- NA
temp_merged$abs_good <- unlist(lapply(temp_merged$type, weight_adder))
temp_merged <- subset(temp_merged, select = -parcel)
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged)
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ]
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id)
View(scenario)
View(scenario)
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
row.names(temp_merged) <- 1:nrow(temp_merged)
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
View(temp_merged)
new_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE))
View(new_scores)
view(data.shape@data)
View(data.shape@data)
source("make_map.R")
View(make_map)
View(make_map)
View(left_join(data.shape@data, new_scores))
View(bg_scores)
source('~/GitHub/planning_dashboard_v2_updated/planning_dashboard_v2/scenario.R')
View(new_scores)
new_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('new_score' = sum(scores, na.rm = TRUE))
View(new_scores)
data.shape <- left_join(data.shape@data, new_scores)
View(data.shape@data)
load("dashboard_map_data.RData")
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
View(data.shape@data)
?colorNumeric
pal <- colorNumeric(
palette = "Green",
domain = data.shape@data$diff_prcnt)
leaflet(data.shape) %>%
addTiles() %>%
addPolygons(stroke = TRUE,opacity = 1,fillOpacity = 0.9, smoothFactor = 0.5,
color=~pal(diff_prcnt),weight = 1) %>%
addLegend("bottomright", pal = pal, values = ~diff_prcnt,
title = "Accessibility Scores Improvement",
labFormat = labelFormat(prefix = ""),
opacity = 1
)
pal <- colorNumeric(
palette = "Green",
domain = data.shape@data$new_score)
leaflet(data.shape) %>%
addTiles() %>%
addPolygons(stroke = TRUE,opacity = 1,fillOpacity = 0.9, smoothFactor = 0.5,
color=~pal(new_score),weight = 1) %>%
addLegend("bottomright", pal = pal, values = ~new_score,
title = "Accessibility Scores Improvement",
labFormat = labelFormat(prefix = ""),
opacity = 1
)
data.shape@data$score_ratio <- data.shape@data$new_score/data.shape@data$access_score
pal <- colorNumeric(
palette = "Green",
domain = data.shape@data$score_ratio)
leaflet(data.shape) %>%
addTiles() %>%
addPolygons(stroke = TRUE,opacity = 1,fillOpacity = 0.9, smoothFactor = 0.5,
color=~pal(score_ratio),weight = 1) %>%
addLegend("bottomright", pal = pal, values = ~score_ratio,
title = "Accessibility Scores Improvement",
labFormat = labelFormat(prefix = ""),
opacity = 1
)
View(data.shape@data)
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)*100
View(data.shape@data)
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
new_maps <- leaflet(data.shape) %>%
addTiles() %>%
addPolygons(stroke = TRUE,opacity = 1,fillOpacity = 0.9, smoothFactor = 0.5,
color=~pal(score_ratio),weight = 1) %>%
addLegend("bottomright", pal = pal, values = ~score_ratio,
title = "Accessibility Scores Improvement",
labFormat = labelFormat(prefix = ""),
opacity = 1
)
new_map <- leaflet(data.shape) %>%
addTiles() %>%
addPolygons(stroke = TRUE,opacity = 1,fillOpacity = 0.9, smoothFactor = 0.5,
color=~pal(score_ratio),weight = 1) %>%
addLegend("bottomright", pal = pal, values = ~score_ratio,
title = "Accessibility Scores Improvement",
labFormat = labelFormat(prefix = ""),
opacity = 1
)
rm(new_maps)
new_map
source('~/GitHub/planning_dashboard_v2_updated/planning_dashboard_v2/make_map.R', echo=TRUE)
new_scores <- scenario()
View(new_scores)
rm(new_scores)
new_scores <- scenario()
View(new_scores)
source('~/GitHub/planning_dashboard_v2_updated/planning_dashboard_v2/make_map.R', echo=TRUE)
make_map()[[1]]
new_scores <- scenario()
View(new_scores)
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
View(data.shape@data)
load("dashboard_map_data.RData")
new_scores <- scenario()
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
View(data.shape@data)
make_map()[[1]]
load("dashboard_map_data.RData")
make_map()[[1]]
runApp()
runApp()
source('~/GitHub/planning_dashboard_v2_updated/planning_dashboard_v2/make_map.R', echo=TRUE)
runApp()
rm(list = ls())
load("dashboard_map_data.RData")
runApp()
runApp()
load("dashboard_data.RData")
load("dashboard_map_data.RData")
runApp()
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
row.names(temp_merged) <- 1:nrow(temp_merged)
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
new_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('new_score' = sum(scores, na.rm = TRUE))
return(new_scores)
runApp()
rm(list = ls())
runApp()
load("dashboard_data.RData")
rm(list = ls())
runApp()
runApp()
new_scores <- scenario()
load("dashboard_data.RData")
load("dashboard_map_data.RData")
runApp()
load("dashboard_data.RData")
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
row.names(temp_merged) <- 1:nrow(temp_merged)
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
new_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('new_score' = sum(scores, na.rm = TRUE))
runApp()
returned_objects()[[2]]
View(data.shape@data)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
source('~/GitHub/planning_dashboard_v2_updated/planning_dashboard_v2/make_map.R', echo=TRUE)
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
base_map
runApp()
runApp()
runApp()
runApp()
runApp()
load("dashboard_map_data.RData")
View(data.shape@data)
data.shape@data$access_score <- new_scores$new_score
View(data.shape@data)
save(bg_scores, merged_data, merged_data_parcels, biking, file = "dashboard_data.RData")
runApp()
new_scores <- scenario()
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
View(data.shape@data)
class(sspz_boundary)
View(sspz_boundary@data)
sspz_bgs <- read.csv('sspzbgpop.csv')
View(sspz_bgs)
?mapply
View(new_scores)
sspz_bgs$spatial_id <- mapply(paste, "0",sspz_bgs)
sspz_bgs$spatial_id <- mapply(paste, "0", sspz_bgs$bg)
sspz_bgs$spatial_id <- mapply(paste, "0", sspz_bgs$bg, sep = "")
save.image()
?filter
View(bg_scores)
filter(bg_scores, spatial_id %in% sspz_bgs$spatial_id)
filter(bg_scores, spatial_id %in% sspz_bgs$spatial_id)$baseline_score
filter(bg_scores, spatial_id %in% sspz_bgs$spatial_id)$baseline_score
sum(filter(bg_scores, spatial_id %in% sspz_bgs$spatial_id)$baseline_score)
runApp()
runApp()
runApp()
runApp()
View(data.shape@data)
load("dashboard_map_data.RData")
View(data.shape@data)
new_scores <- scenario()
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
runApp()
data.shape@data <- left_join(data.shape@data, new_scores, by = "spatial_id")
data.shape@data$score_ratio <- (data.shape@data$new_score/data.shape@data$access_score)
View(data.shape@data)
load("dashboard_map_data.RData")
View(data.shape@data)
runApp()
runApp()
runApp()
runApp()
