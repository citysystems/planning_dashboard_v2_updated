View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- 1:100
a2 <- 1:100
a3 <- 1:100
y <- a1*rnorm(100, mean = 12, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
12+4+5
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- 1:100
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- 1:100
y <- a1*rnorm(100, mean = 12, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 12, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 2, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
library(MASS)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
# y <- a1*rnorm(100, mean = 2, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
library(MASS)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
# y <- a1*rnorm(100, mean = 2, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
# y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
# y <- a1*rnorm(100, mean = 2, sd = 4) + a2*rnorm(100, mean = 4, sd = 7) + a3*rnorm(100, mean = 5, sd = 2)
y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 2, sd = 0.01) + a2*rnorm(100, mean = 4, sd = 0.01) + a3*rnorm(100, mean = 5, sd = 0.01)
# y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100*rnorm(100, mean = 2)
# a2 <- rnorm(100, mean = 0, sd = 20)*rnorm(100, mean = 4)
# a3 <- rnorm(100, mean = 50, sd = 20)*rnorm(100, mean = 5)
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 2, sd = 0.01) + a2*rnorm(100, mean = 4, sd = 0.01) + a3*rnorm(100, mean = 5, sd = 0.01) + rnorm(100, mean = 0.1, sd = 1)
# y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
plot( y ~ A[,1])
View(A)
plot( y ~ A[,2])
plot( y ~ A[,3])
plot( y ~ A[,4])
View(X_hat)
a1 <- 1:100
a2 <- 1:100
a3 <- 1:100
# a1 <- rnorm(100, mean = 250, sd = 50)
# a2 <- rnorm(100, mean = 100, sd = 50)
# a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 2, sd = 0.01) + a2*rnorm(100, mean = 4, sd = 0.01) + a3*rnorm(100, mean = 5, sd = 0.01) + rnorm(100, mean = 0.1, sd = 1)
# y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
# a1 <- 1:100
# a2 <- 1:100
# a3 <- 1:100
a1 <- rnorm(100, mean = 250, sd = 50)
a2 <- rnorm(100, mean = 100, sd = 50)
a3 <- rnorm(100, mean = 75, sd = 50)
y <- a1*rnorm(100, mean = 2, sd = 0.01) + a2*rnorm(100, mean = 4, sd = 0.01) + a3*rnorm(100, mean = 5, sd = 0.01) + rnorm(100, mean = 0.1, sd = 1)
# y <- 2*a1 + 4*a2 + 5*a3
y <- matrix(y, ncol = 1)
A <- matrix(c(rep(1,100), a1, a2, a3), ncol = 4)
X_hat <- ginv(A)%*%y
View(X_hat)
X_hat <- solve(t(A)%*%A)%*%t(A)%*%y
View(X_hat)
View(country_list)
rbinom(10,1,0.5)
rbinom(10,1,0.5)
rbinom(1,10,0.5)
rbinom(1,15,0.5)
rbinom(1,20,0.5)
rbinom(10,1,0.5)
library(readr)
library(dplyr)
library(tidyr)
library(rgdal)
library(sp)
library(leaflet)
library(tidyr)
library(googlesheets)
parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
row.names(parcel_proposals) <- parcel_proposals$APN
parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
getwd()
shiny::runApp('C:/Users/Max/Dropbox/City_Systems/Scores_Tools/planning_dashboard/planning_dashboard_v2/planning_dashboard_v2')
runApp('C:/Users/Max/Dropbox/City_Systems/Scores_Tools/planning_dashboard/planning_dashboard_v2/planning_dashboard_v2')
runApp('C:/Users/Max/Dropbox/City_Systems/Scores_Tools/planning_dashboard/planning_dashboard_v2/planning_dashboard_v2')
runApp('C:/Users/Max/Dropbox/City_Systems/Scores_Tools/planning_dashboard/planning_dashboard_v2/planning_dashboard_v2')
shinyApp(ui,server)
getwd()
setwd("C:\\Users\\Max\\Dropbox\\City_Systems\\Scores_Tools\\planning_dashboard\\planning_dashboard_v2\\planning_dashboard_v2")
getwd()
rm(list = ls())
ls()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
load("dashboard_data.RData")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
load("dashboard_data.RData")
# Libraries used for building
library(dplyr)
View(subset(bg_scores, select = c(spatial_id, access_score2)))
bg_scores <- subset(bg_scores, select = c(spatial_id, access_score2))
save(bg_scores, merged_data, merged_data_parcels, biking, file = "dashboard_data.RData")
View(bg_scores)
View(bg_scores)
names(bg_scores)[2]
names(bg_scores)[2] <- "baseline_score"
save(bg_scores, merged_data, merged_data_parcels, biking, file = "dashboard_data.RData")
shiny::runApp()
runApp()
sum(bg_scores$baseline_score
)
View(bg_scores)
load("dashboard_map_data.RData")
base_map
library(sp)
shiny::runApp()
runApp()
runApp()
runApp()
sum(bg_scores$baseline_score)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
load("dashboard_data.RData")
load("dashboard_map_data.RData")
View(subset(bg_scores, select = c(spatial_id, access_score2)))
bg_scores <- subset(bg_scores, select = c(spatial_id, access_score2))
names(bg_scores)[2]
names(bg_scores)[2] <- baseline_score
names(bg_scores)[2] <- "baseline_score"
save(bg_scores, merged_data, merged_data_parcels, bikin
load("dashboard_data.RData")
load("dashboard_map_data.RData")
save(bg_scores, merged_data, merged_data_parcels, biking, file = "dashboard_data.RData")
load("dashboard_data.RData")
load("dashboard_map_data.RData")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
output$benchmap <- renderLeaflet({base_map})
library(leaflet)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
source("rank_fixer.R")
source("scenario.R")
source("rank_fixer.R")
source("score_calc.R")
source("type_splitter.R")
source("weight_adder.R")
source("scenario.R")
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
library(googlesheets)
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
library(tidyr)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
getwd()
setwd("C:/Users/Derek/Documents/CS_work/scores_calculation")
load(".RData")
save(bg_scores, merged_data, merged_data_parcels, biking, amenity_info, file = "dashboard_data.RData")
setwd("C:/Users/Derek/Documents/CS_work/planning_dashboard_v2")
rm(list = ls(0))
rm(list = ls())
getwd(0)
getwd()
load("dashboard_data.RData")
load("dashboard_map_data.RData")
library(shiny)
library(sp)
library(leaflet)
library(googlesheets)
library(tidyr)
source("rank_fixer.R")
source("score_calc.R")
source("type_splitter.R")
source("weight_adder.R")
source("scenario.R")
# Libraries and code used for building
library(dplyr)
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
source("marg_good_func.R")
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
View(scenario)
View(scenario)
View(temp_merged)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
View(bg_scores)
View(bg_scores)
513.83130
load("dashboard_data.RData")
View(bg_scores)
load("dashboard_data.RData")
View(base_map)
View(base_map)
View(bg_scores)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
source('~/CS_work/planning_dashboard_v2/scenario.R')
toc()
# Libraries and code used for building
library(tictoc)
scenario <- function() {
# I don't think anything needs to be sent in, it just needs to return the new scores somehow.
tic()
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# View(type_counts)
# Really just for testing.
# parcel_proposals %>% group_by(type) %>% summarize(n())
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
# Now just need to append the two dataframes and update the ranks where appropriate
# For now, I'll just keep all but could easily trim each subset to only the desired amount of each amenity.
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
toc()
}
tic()
# Load proposals
sheet_url <- "https://docs.google.com/spreadsheets/d/1R7dxLoPc-AjvmsdbExF5i2XyfMtZHIG24ziTj-er8Rk/"
# parcel_proposals <- read_csv("./inputs/parcel_proposals.csv", col_types = cols(APN = col_character(), type = col_character()))
parcel_proposals <- gs_url(sheet_url) %>% gs_read("Sheet1", range = "A1:E60")
parcel_proposals$APN <- as.character(parcel_proposals$APN)
row.names(parcel_proposals) <- parcel_proposals$APN
# Load the weights
weights_url <- "https://docs.google.com/spreadsheets/d/18_XTChwbtd8dMn_7WDp_qXF6d_VXAhRexgjQTgJq0NY/"
weights <- gs_url(weights_url) %>% gs_read("Sheet1", range = "A1:R18")
row.names(weights) <- weights$type
parcel_proposals <- parcel_proposals %>% subset(select = -name)
parcel_proposals <- parcel_proposals %>% gather(num, type, -APN) %>% subset(select = -num)
parcel_proposals <- parcel_proposals[complete.cases(parcel_proposals$type),]
new_parcel_types <- unique(parcel_proposals$type)
# tk - For now I'm manually addressing types with scores of zero, should be able to come up with a better fix later.
new_parcel_types <- new_parcel_types[new_parcel_types != 'vacant']
type_counts <- unlist(lapply(new_parcel_types, function(p_type) return( nrow(parcel_proposals[parcel_proposals$type == p_type,]))))
names(type_counts) <- new_parcel_types
# View(type_counts)
# Really just for testing.
# parcel_proposals %>% group_by(type) %>% summarize(n())
# temp_merged <- merged_data_parcels
# This is exactly what I needed.
temp_merged <- merged_data_parcels %>% full_join(parcel_proposals, by = c( "parcel" = "APN"))
temp_merged$rank <- NA
temp_merged <- weight_adder(temp_merged, weights)
# Now just need to append the two dataframes and update the ranks where appropriate
# For now, I'll just keep all but could easily trim each subset to only the desired amount of each amenity.
temp_merged <- subset(temp_merged, select = -parcel) # >
temp_merged <- rbind(merged_data[,names(temp_merged)], temp_merged) # >
temp_merged <- temp_merged[order(temp_merged$spatial_id, temp_merged$type, temp_merged$crow_distance), ] # >
# tk - eventually needs to change. I think this is fine because I'm using the current definitive lists.
temp_merged <- temp_merged %>% filter(spatial_id %in% biking$spatial_id) # >
temp_merged <- temp_merged[complete.cases(temp_merged$crow_distance),] # >
# Duplicate row names seem to be throwing off the boolean indexing
row.names(temp_merged) <- 1:nrow(temp_merged)
# tk - drop the unwanted categories here?
temp_merged <- temp_merged[temp_merged$type != 'vacant', ]
temp_merged <- bind_rows(lapply(split.data.frame(temp_merged, f = temp_merged$spatial_id), type_splitter))
# Removing the NA ranks.
temp_merged <- temp_merged[complete.cases(temp_merged$rank),]
temp_merged$scores <- score_calc(temp_merged$time_biking, temp_merged$time_driving, temp_merged$time_transit, temp_merged$time_walking, temp_merged$abs_good, temp_merged$rank, temp_merged$type)
bg_scores <- temp_merged %>% group_by(spatial_id) %>% summarise('access_score2' = sum(scores, na.rm = TRUE)) %>% left_join(bg_scores)
bg_scores$diff <- bg_scores$access_score2- bg_scores$access_score
bg_scores$diff_prcnt <- bg_scores$access_score2/bg_scores$access_score
toc()
View(bg_scores)
runApp()
View(subset(bg_scores, select = c(spatial_id, access_score2)))
bg_scores <- subset(bg_scores, select = c(spatial_id, access_score2))
names(bg_scores)[2] <- "baseline_score"
runApp()
View(base_map)
View(bg_scores)
save(bg_scores, merged_data, merged_data_parcels, biking, amenity_info, file = "dashboard_data.RData")
load("dashboard_data.RData")
View(bg_scores)
runApp()
runApp()
